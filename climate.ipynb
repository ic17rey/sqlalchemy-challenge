{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SQLAlchemy Challenge - Surfs Up!\n",
    "\n",
    "### Before You Begin\n",
    "\n",
    "1. Create a new repository for this project called `sqlalchemy-challenge`. **Do not add this homework to an existing repository**.\n",
    "\n",
    "2. Clone the new repository to your computer.\n",
    "\n",
    "3. Add your Jupyter notebook and `app.py` to this folder. These will be the main scripts to run for analysis.\n",
    "\n",
    "4. Push the above changes to GitHub or GitLab.\n",
    "\n",
    "\n",
    "Congratulations! You've decided to treat yourself to a long holiday vacation in Honolulu, Hawaii! To help with your trip planning, you need to do some climate analysis on the area. The following outlines what you need to do.\n",
    "\n",
    "## Step 1 - Climate Analysis and Exploration\n",
    "\n",
    "To begin, use Python and SQLAlchemy to do basic climate analysis and data exploration of your climate database. All of the following analysis should be completed using SQLAlchemy ORM queries, Pandas, and Matplotlib.\n",
    "\n",
    "* Use the provided starter notebook and hawaii.sqlite files to complete your climate analysis and data exploration.\n",
    "\n",
    "* Use SQLAlchemy `create_engine` to connect to your sqlite database.\n",
    "\n",
    "* Use SQLAlchemy `automap_base()` to reflect your tables into classes and save a reference to those classes called `Station` and `Measurement`.\n",
    "\n",
    "* Link Python to the database by creating an SQLAlchemy session.\n",
    "\n",
    "* **Important** Don't forget to close out your session at the end of your notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available matplotlib backends: ['tk', 'gtk', 'gtk3', 'wx', 'qt4', 'qt5', 'qt', 'osx', 'nbagg', 'notebook', 'agg', 'svg', 'pdf', 'ps', 'inline', 'ipympl', 'widget']\n"
     ]
    }
   ],
   "source": [
    "%matplotlib --list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import style\n",
    "style.use('fivethirtyeight')\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Solarize_Light2',\n",
       " '_classic_test_patch',\n",
       " 'bmh',\n",
       " 'classic',\n",
       " 'dark_background',\n",
       " 'fast',\n",
       " 'fivethirtyeight',\n",
       " 'ggplot',\n",
       " 'grayscale',\n",
       " 'seaborn',\n",
       " 'seaborn-bright',\n",
       " 'seaborn-colorblind',\n",
       " 'seaborn-dark',\n",
       " 'seaborn-dark-palette',\n",
       " 'seaborn-darkgrid',\n",
       " 'seaborn-deep',\n",
       " 'seaborn-muted',\n",
       " 'seaborn-notebook',\n",
       " 'seaborn-paper',\n",
       " 'seaborn-pastel',\n",
       " 'seaborn-poster',\n",
       " 'seaborn-talk',\n",
       " 'seaborn-ticks',\n",
       " 'seaborn-white',\n",
       " 'seaborn-whitegrid',\n",
       " 'tableau-colorblind10']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.style.available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reflect Tables into SQLAlchemy ORM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python SQL toolkit and Object Relational Mapper\n",
    "import sqlalchemy\n",
    "from sqlalchemy.ext.automap import automap_base\n",
    "from sqlalchemy.orm import Session\n",
    "from sqlalchemy import create_engine, func, inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a variable for the path\n",
    "database_path = 'Resources/hawaii.sqlite'\n",
    "\n",
    "# create engine to hawaii.sqlite\n",
    "engine = create_engine(f'sqlite:///{database_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reflect an existing database into a new model\n",
    "\n",
    "# reflect the tables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reflect an existing database into a new model\n",
    "\n",
    "# Declare a Base and prepare the Base class to reflect the tables\n",
    "Base = automap_base()\n",
    "Base.prepare(engine, reflect=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['measurement', 'station']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reflect the tables\n",
    "Base.classes.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['measurement', 'station']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspecting the tables\n",
    "inspector = inspect(engine)\n",
    "inspector.get_table_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id INTEGER\n",
      "station TEXT\n",
      "date TEXT\n",
      "prcp FLOAT\n",
      "tobs FLOAT\n"
     ]
    }
   ],
   "source": [
    "# View all of the classes that automap found, starting with 'measurement'\n",
    "columns = inspector.get_columns('measurement')\n",
    "for column in columns:\n",
    "    print(column['name'], column['type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id INTEGER\n",
      "station TEXT\n",
      "name TEXT\n",
      "latitude FLOAT\n",
      "longitude FLOAT\n",
      "elevation FLOAT\n"
     ]
    }
   ],
   "source": [
    "# View the second class that automap found, 'station'\n",
    "columns = inspector.get_columns('station')\n",
    "for column in columns:\n",
    "    print(column['name'], column['type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save references to each table\n",
    "Measurement = Base.classes.measurement\n",
    "Station = Base.classes.station\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create our session (link) from Python to the DB\n",
    "session = Session(engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precipitation Analysis\n",
    "\n",
    "* Start by finding the most recent date in the data set.\n",
    "\n",
    "* Using this date, retrieve the last 12 months of precipitation data by querying the 12 preceding months of data. **Note** you do not pass in the date as a variable to your query.\n",
    "\n",
    "* Select only the `date` and `prcp` values.\n",
    "\n",
    "* Load the query results into a Pandas DataFrame and set the index to the date column.\n",
    "\n",
    "* Sort the DataFrame values by `date`.\n",
    "\n",
    "* Plot the results using the DataFrame `plot` method.\n",
    "\n",
    "* Use Pandas to print the summary statistics for the precipitation data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Precipitation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the most recent date in the data set.\n",
    "\n",
    "# Order descending and then use .first()?\n",
    "# session.query(nameLikeDow.date).order_by(Dow.date.desc()).first()\n",
    "    # add in the prcp to the above session as well (maybe like *sel where sel = date and prcp?)\n",
    "\n",
    "    # then for next step will be something like:\n",
    "# session.query(Dow.date).filter(Dow.date > '2011-03-01').order_by(Dow.date.desc()).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Design a query to retrieve the last 12 months of precipitation data and plot the results. \n",
    "# Starting from the most recent data point in the database. \n",
    "\n",
    "# Calculate the date one year from the last date in data set.\n",
    "\n",
    "\n",
    "# Perform a query to retrieve the data and precipitation scores\n",
    "\n",
    "\n",
    "# Save the query results as a Pandas DataFrame and set the index to the date column\n",
    "\n",
    "\n",
    "# Sort the dataframe by date\n",
    "\n",
    "\n",
    "# Use Pandas Plotting with Matplotlib to plot the data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Pandas to calcualte the summary statistics for the precipitation data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Station Analysis\n",
    "\n",
    "* Design a query to calculate the total number of stations in the dataset.\n",
    "\n",
    "* Design a query to find the most active stations (i.e. which stations have the most rows?).\n",
    "\n",
    "  * List the stations and observation counts in descending order.\n",
    "\n",
    "  * Which station id has the highest number of observations?\n",
    "\n",
    "  * Using the most active station id, calculate the lowest, highest, and average temperature.\n",
    "\n",
    "  * Hint: You will need to use a function such as `func.min`, `func.max`, `func.avg`, and `func.count` in your queries.\n",
    "\n",
    "* Design a query to retrieve the last 12 months of temperature observation data (TOBS).\n",
    "\n",
    "  * Filter by the station with the highest number of observations.\n",
    "\n",
    "  * Query the last 12 months of temperature observation data for this station.\n",
    "\n",
    "  * Plot the results as a histogram with `bins=12`.\n",
    "\n",
    "* Close out your session."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Station Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Design a query to calculate the total number stations in the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Design a query to find the most active stations (i.e. what stations have the most rows?)\n",
    "# List the stations and the counts in descending order.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the most active station id from the previous query, calculate the lowest, highest, and average temperature.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the most active station id\n",
    "# Query the last 12 months of temperature observation data for this station and plot the results as a histogram\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Close session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close Session\n",
    "session.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once above is complete move on to step two which will be in the app.py file\n",
    "\n",
    "## Step 2 - Climate App\n",
    "\n",
    "Now that you have completed your initial analysis, design a Flask API based on the queries that you have just developed.\n",
    "\n",
    "* Use Flask to create your routes.   --MORE info in the readme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "nteract": {
   "version": "0.12.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
